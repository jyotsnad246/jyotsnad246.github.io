<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Hi, I&#39;m Jyotsna</title>
        <link>https://jyotsnad246.github.io/posts/</link>
        <description>Recent content in Posts on Hi, I&#39;m Jyotsna</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 05 Jan 2025 00:00:00 +0000</lastBuildDate>
        <atom:link href="https://jyotsnad246.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Exploring Machine Learning using C&#43;&#43;</title>
            <link>https://jyotsnad246.github.io/posts/2023/08/exploring-machine-learning-using-c-/</link>
            <pubDate>Tue, 29 Aug 2023 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2023/08/exploring-machine-learning-using-c-/</guid>
            <description>Exploring C++ Libraries for Machine Learning: An overview of popular C++ libraries for machine learning, such as TensorFlow, Caffe, or MXNet, highlighting their features and use cases.
Machine learning has revolutionized the way we solve complex problems, and C++ has long been a reliable language for building robust and efficient applications. In this blog post, we will embark on an exciting journey to explore three popular C++ libraries for machine learning: TensorFlow, Caffe, and MXNet.</description>
            <content type="html"><![CDATA[<blockquote>
<p>Exploring C++ Libraries for Machine Learning: An overview of popular C++ libraries for machine learning, such as TensorFlow, Caffe, or MXNet, highlighting their features and use cases.</p>
</blockquote>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*C9DiGk1kRDJMr1UlfUXBMg.jpeg" alt=""></p>
<p>Machine learning has revolutionized the way we solve complex problems, and C++ has long been a reliable language for building robust and efficient applications. In this blog post, we will embark on an exciting journey to explore three popular C++ libraries for machine learning: TensorFlow, Caffe, and MXNet. We’ll dive into their unique features, use cases, and provide code snippets to illustrate their power. So, fasten your seatbelts and get ready to unleash the full potential of these libraries!</p>
<h2 id="1-tensorflow-an-end-to-end-machine-learning-framework"><strong>1. TensorFlow: An End-to-End Machine Learning Framework</strong></h2>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*YrvMKrWMhi3HomoiTLPsfw.png" alt=""></p>
<p>TensorFlow has gained immense popularity for its versatility and comprehensive suite of tools. Let’s start by exploring some of its key features:</p>
<ul>
<li>TensorFlow provides a highly flexible computation graph that allows you to define and execute complex mathematical operations efficiently.</li>
<li>Its extensive library of pre-built functions and algorithms simplifies the process of building deep neural networks. TensorFlow also provides pre-built functions and APIs for common tasks, making it easier to get started.</li>
<li>TensorFlow’s eager execution mode enables you to dynamically evaluate operations as they are executed, making it easier for debugging and prototyping.</li>
</ul>
<p>To give you a taste of TensorFlow’s capabilities, let’s look at a code snippet for training a simple feedforward neural network in C++ :</p>
<pre><code>#include &lt;tensorflow/cc/client/client_session.h&gt;
#include &lt;tensorflow/cc/ops/standard_ops.h&gt;

using namespace tensorflow;
using namespace tensorflow::ops;

int main() {
  Scope root = Scope::NewRootScope();

  // Define placeholders for input and labels
  auto input = Placeholder(root, DT_FLOAT);
  auto labels = Placeholder(root, DT_FLOAT);

  // Define the neural network architecture
  auto weights = Variable(root, {784, 10}, DT_FLOAT);
  auto biases = Variable(root, {10}, DT_FLOAT);
  auto logits = Add(root, MatMul(root, input, weights), biases);

  // Define the loss function
  auto loss = ReduceMean(root, Square(root, Subtract(root, logits, labels)), {0});

  // Create an optimizer and minimize the loss
  auto optimizer = GradientDescentOptimizer(root, 0.01);
  auto train_op = optimizer.minimize(loss);

  // Initialize a session and train the model
  ClientSession session(root);
  TF_CHECK_OK(session.Run({{input, input_data}, {labels, label_data}}, {train_op}));

  return 0;
}
</code></pre>
<p>This code demonstrates how TensorFlow allows you to define a neural network architecture, calculate the loss, create an optimizer, and train the model, all within a concise and intuitive API.</p>
<h2 id="2-caffe-fast-and-efficient-deep-learning">2. Caffe: Fast and Efficient Deep Learning</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:600/1*3WUg_lq6KmN7Kl1uhZGDKg.png" alt=""></p>
<p>Caffe is a powerful library known for its speed and efficiency, making it an excellent choice for large-scale deep learning projects. Here are some highlights of Caffe’s features:</p>
<ul>
<li>Caffe provides a simple and expressive architecture for defining deep neural networks using its own configuration files.</li>
<li>It leverages GPU acceleration to achieve lightning-fast training and inference.</li>
<li>Caffe offers a rich collection of pre-trained models that can be fine-tuned or used directly for various tasks like image classification, object detection, and more.</li>
</ul>
<p>Let’s take a glimpse at a code snippet that demonstrates loading a pre-trained model and performing image classification using Caffe:</p>
<pre><code>#include &lt;caffe/caffe.hpp&gt;

using namespace caffe;

int main() {
  // Load the pre-trained model and its weights
  Net&lt;float&gt; net(&quot;deploy.prototxt&quot;, TEST);
  net.CopyTrainedLayersFrom(&quot;weights.caffemodel&quot;);

  // Load and preprocess the input image
  cv::Mat image = cv::imread(&quot;input.jpg&quot;);
  cv::Mat inputBlob = Blob&lt;float&gt;(image);

  // Perform forward pass to obtain predictions
  std::vector&lt;Blob&lt;float&gt;&gt; outputBlobs;
  net.ForwardPrefilled(&amp;outputBlobs);

  // Print the top predicted classes and their probabilities
  std::vector&lt;float&gt; predictions = outputBlobs[0].cpu_data();
  std::vector&lt;int&gt; top_classes = GetTopKClasses(predictions, 5);

  for (int i = 0; i &lt; top_classes.size(); ++i) {
    int class_id = top_classes[i];
    float probability = predictions[class_id];
    std::cout &lt;&lt; &quot;Class: &quot; &lt;&lt; class_id &lt;&lt; &quot;, Probability: &quot; &lt;&lt; probability &lt;&lt; std::endl;
  }

  return 0;
}
</code></pre>
<p>This snippet showcases Caffe’s ability to load a pre-trained model, preprocess an input image, perform a forward pass, and retrieve the top predicted classes along with their probabilities in C++.</p>
<h2 id="3-mxnet-scalable-and-flexible-deep-learning">3. MXNet: Scalable and Flexible Deep Learning</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:500/1*bH_vdFJkA4SQ0lKe76hRiQ.png" alt=""></p>
<p>MXNet stands out as a powerful library that emphasizes both scalability and flexibility. Its unique features make it a go-to choice for developing machine learning models. Let’s explore some of its key attributes:</p>
<ul>
<li>MXNet offers a hybrid programming model that allows you to seamlessly switch between imperative and symbolic execution modes, combining the best of both worlds.</li>
<li>It provides support for distributed computing, enabling you to train models across multiple devices or even on distributed clusters.</li>
<li>MXNet boasts a comprehensive set of high-level APIs for various machine learning tasks, including computer vision, natural language processing, and reinforcement learning.</li>
</ul>
<p>To showcase the versatility of MXNet, let’s take a look at a code snippet for training a convolutional neural network using the symbolic API:</p>
<pre><code>#include &lt;mxnet-cpp/MxNetCpp.h&gt;

using namespace mxnet::cpp;

int main() {
  // Create a symbolic variable for the input data
  Symbol input = Symbol::Variable(&quot;data&quot;);

  // Define the neural network architecture
  Symbol conv1 = Convolution(&quot;conv1&quot;, input, Symbol(), Shape(5, 5), 32);
  Symbol relu1 = Activation(&quot;relu1&quot;, conv1, &quot;relu&quot;);
  Symbol pool1 = Pooling(&quot;pool1&quot;, relu1, Shape(2, 2), &quot;max&quot;, Shape(2, 2));

  // ... Add more layers and define the rest of the architecture

  // Define the loss function and output symbol
  Symbol output = FullyConnected(&quot;fc1&quot;, pool2, num_classes);

  // Create the executor for training
  Context ctx = Context::gpu();
  std::map&lt;std::string, NDArray&gt; args_map;
  args_map[&quot;data&quot;] = NDArray(Shape(batch_size, input_channels, input_height, input_width), ctx);
  args_map[&quot;label&quot;] = NDArray(Shape(batch_size), ctx);
  Executor* executor = output.SimpleBind(ctx, args_map);

  // Train the model and update the weights
  // ...

  return 0;
}
</code></pre>
<p>This code demonstrates MXNet’s symbolic API by defining a convolutional neural network architecture, creating an executor for training, and preparing the input data. MXNet’s flexibility shines through its ability to seamlessly integrate with different backends and adapt to various use cases.</p>
<h2 id="4-shark-universal-machine-learning-library">4. SHARK: Universal Machine Learning Library</h2>
<p><a href="https://trola.org/images/wp/2013/02/SharkLogo.png"></a></p>
<p><img src="https://miro.medium.com/v2/resize:fit:399/1*WtWABXbKiqNYQvkosvA1oQ.png" alt=""></p>
<p>SHARK is an open-source machine learning library that provides a wide range of algorithms and functionalities. Let’s explore some of its key features:</p>
<ul>
<li>SHARK supports various machine learning methods, including neural networks, linear and nonlinear optimization, kernel-based learning algorithms, and more.</li>
<li>It provides a modular and flexible design, allowing users to easily combine different components and algorithms.</li>
<li>SHARK is known for its performance and scalability, making it suitable for both small-scale experiments and large-scale applications.</li>
</ul>
<p>To give you a glimpse of SHARK’s capabilities, let’s look at a code snippet for training a Support Vector Machine (SVM) using SHARK:</p>
<pre><code>#include &lt;shark/Algorithms/Trainers/SVMTrainer.h&gt;
#include &lt;shark/Models/Kernels/GaussianRbfKernel.h&gt;

using namespace shark;

int main() {
  // Load the training data
  ClassificationDataset dataset;
  dataset.load(&quot;train_data.csv&quot;);

  // Configure the SVM trainer
  SVMTrainer&lt;RealVector&gt; trainer;
  trainer.setKernel(GaussianRbfKernel&lt;&gt;(0.5)); // Set the RBF kernel with gamma = 0.5
  trainer.setC(1.0); // Set the regularization parameter

  // Train the SVM model
  ClassificationDataset::PartitionedDatasetType partitions = dataset.splitAtRatio(0.8);
  trainer.train(model, partitions.training);

  // Evaluate the trained model
  Data&lt;RealVector&gt; test_data = partitions.test.inputs();
  Data&lt;RealVector&gt; predictions = model(test_data);
  double accuracy = classificationError(partitions.test.labels(), predictions.labels());

  std::cout &lt;&lt; &quot;Accuracy: &quot; &lt;&lt; accuracy &lt;&lt; std::endl;

  return 0;
}
</code></pre>
<p>This code demonstrates how SHARK allows you to load a dataset, configure an SVM trainer with a Gaussian RBF kernel, train the model, and evaluate its accuracy.</p>
<h2 id="5-armadillo-linear-algebra-package-with-matlab-like-features">5. Armadillo: Linear Algebra Package with MATLAB like Features</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*76Yu_UYRRX4OsKUGvTkCGw.png" alt=""></p>
<p>Armadillo is a powerful linear algebra library that provides Matlab-like features for C++. Let’s explore some highlights of Armadillo’s features:</p>
<ul>
<li>Armadillo offers an easy-to-use interface with syntax similar to Matlab, making it effortless to translate research code across various fields.</li>
<li>The library supports various linear algebra operations, such as matrix and vector manipulation, matrix factorizations, solving linear systems, and more.</li>
<li>Armadillo is widely used in fields like pattern recognition, computer vision, signal processing, bioinformatics, statistics, and econometrics.</li>
</ul>
<p>To demonstrate Armadillo’s capabilities, let’s look at a code snippet for performing matrix operations and solving a linear system:</p>
<pre><code>#include &lt;armadillo&gt;

using namespace arma;

int main() {
  // Create matrices and vectors
  mat A = {{1.0, 2.0, 3.0},
           {4.0, 5.0, 6.0},
           {7.0, 8.0, 10.0}};
  vec b = {3.0, 4.0, 5.0};

  // Perform matrix operations
  mat B = A.t(); // Transpose of matrix A
  mat C = A + B; // Matrix addition
  mat D = A * B; // Matrix multiplication

  // Solve a linear system
  vec x = solve(A, b); // Solves Ax = b

  // Print the results
  std::cout &lt;&lt; &quot;Matrix A:\n&quot; &lt;&lt; A &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Transpose of A:\n&quot; &lt;&lt; B &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Matrix addition (A + B):\n&quot; &lt;&lt; C &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Matrix multiplication (A * B):\n&quot; &lt;&lt; D &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Solution to Ax = b:\n&quot; &lt;&lt; x &lt;&lt; std::endl;

  return 0;
}
</code></pre>
<p>Armadillo’s intuitive syntax and extensive functionality make it a valuable tool for various fields, including pattern recognition, computer vision, signal processing, bioinformatics, statistics, and econometrics. Whether you need to manipulate matrices, solve linear systems, or perform advanced linear algebra operations, Armadillo’s Matlab-like features provide a convenient and powerful environment for your C++ machine learning projects.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this blog post, we have explored five powerful C++ libraries for machine learning: TensorFlow, Caffe, MXNet, SHARK, and Armadillo. Each library brings its unique features, making them suitable for different use cases. TensorFlow provides end-to-end machine learning capabilities, while Caffe focuses on fast and efficient deep learning. MXNet offers scalability and flexibility, SHARK provides a wide range of algorithms, and Armadillo simplifies linear algebra operations. Armed with this knowledge, you are now equipped to explore and leverage these powerful libraries to tackle a wide range of machine learning challenges using C++.</p>
]]></content>
        </item>
        
        <item>
            <title>Unleashing the Power of Deep Learning - Natural Language Processing in Finance</title>
            <link>https://jyotsnad246.github.io/posts/2023/05/unleashing-the-power-of-deep-learning-natural-language-processing-in-finance/</link>
            <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2023/05/unleashing-the-power-of-deep-learning-natural-language-processing-in-finance/</guid>
            <description>Introduction In recent years, the intersection of deep learning and natural language processing (NLP) has revolutionized various industries, including finance. By leveraging the capabilities of deep learning models, financial institutions can extract valuable insights from vast amounts of unstructured textual data. This article explores the application of deep learning in NLP for finance, highlighting its potential to enhance decision-making processes, sentiment analysis, and automated financial reporting.
Understanding Deep Learning Deep learning is a subset of machine learning that focuses on training artificial neural networks with multiple layers to learn hierarchical representations of data.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In recent years, the intersection of deep learning and natural language processing (NLP) has revolutionized various industries, including finance. By leveraging the capabilities of deep learning models, financial institutions can extract valuable insights from vast amounts of unstructured textual data. This article explores the application of deep learning in NLP for finance, highlighting its potential to enhance decision-making processes, sentiment analysis, and automated financial reporting.</p>
<p><a href="https://unsplash.com/photos/amLfrL8LGls"></a></p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/0*r2YdDKBT1P1ZP1Wm" alt=""></p>
<h2 id="understanding-deep-learning">Understanding Deep Learning</h2>
<p>Deep learning is a subset of machine learning that focuses on training artificial neural networks with multiple layers to learn hierarchical representations of data. These neural networks are capable of automatically learning and extracting complex patterns from raw data, making them well-suited for processing and understanding textual information.</p>
<h3 id="1-sentiment-analysis-and-news-sentiment-indicators">1. Sentiment Analysis and News Sentiment Indicators</h3>
<p>Sentiment analysis plays a crucial role in understanding market dynamics and investor sentiment. Deep learning models, such as recurrent neural networks (RNNs) and transformers, can effectively capture semantic and contextual information from textual data. By training on historical data, these models can classify news articles, social media posts, and financial reports into sentiment categories like positive, negative, or neutral. The aggregation of sentiment analysis results across various sources can provide valuable insights and help construct news sentiment indicators.</p>
<h3 id="2-named-entity-recognition-and-information-extraction">2. Named Entity Recognition and Information Extraction</h3>
<p>Named Entity Recognition (NER) is another important task in financial NLP. Deep learning models can be trained to identify and extract entities such as company names, financial indicators, or key personnel from unstructured textual data. This information can be utilized for various purposes, including risk assessment, investment analysis, and compliance.</p>
<h3 id="3-automated-financial-reporting">3. Automated Financial Reporting</h3>
<p>Deep learning models can automate the process of generating financial reports. By training on large corpora of financial documents, such as annual reports or SEC filings, these models can learn to extract relevant financial information, analyze financial statements, and identify key insights. By automating this process, financial institutions can save time and resources while ensuring accurate and standardized reporting.</p>
<h3 id="4-predictive-analysis">4. Predictive Analysis</h3>
<p>One of the notable ways in which machine learning is revolutionizing the field of finance is through its application in predictive analytics. Predictive analytics involves leveraging historical data to make informed predictions about future events. This powerful technique finds application across various financial domains, including stock price forecasting, fraud detection, and credit risk assessment. By processing vast amounts of data, machine learning algorithms can uncover hidden patterns and generate accurate predictions with a significant level of certainty.</p>
<h2 id="various-other-applications">Various Other Applications</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:651/1*feFU1ZMxqmfIQNIBeENKgA.png" alt=""></p>
<h2 id="addressing-challenges-that-may-occur">Addressing Challenges That May Occur</h2>
<p>While deep learning for NLP in finance brings promising opportunities, it also presents certain challenges.</p>
<ul>
<li>One challenge is the need for high-quality labeled data for model training.</li>
<li>Additionally, financial language is often domain-specific, requiring specialized training data and fine-tuning techniques.</li>
<li>Furthermore, model interpretability is crucial in finance, and efforts are being made to develop techniques that explain the decisions made by deep learning models.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Deep learning has unleashed the power of AI in the field of natural language processing for finance. By leveraging deep learning models, financial institutions can gain actionable insights from vast amounts of unstructured textual data, enhancing decision-making processes, sentiment analysis, and automated financial reporting. As technology continues to advance, the application of deep learning in finance is poised to transform the industry and drive further innovation.</p>
]]></content>
        </item>
        
        <item>
            <title>The Dutch National Flag Algorithm: Efficient Sorting in Three Categories</title>
            <link>https://jyotsnad246.github.io/posts/2025/01/the-dutch-national-flag-algorithm-efficient-sorting-in-three-categories/</link>
            <pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2025/01/the-dutch-national-flag-algorithm-efficient-sorting-in-three-categories/</guid>
            <description>The Dutch National Flag algorithm is a popular and efficient sorting technique for problems where elements can be divided into three distinct categories. Named after the Dutch national flag, where there are three horizontal stripes of different colors, this algorithm elegantly sorts an array of items into three groups with minimal swaps and comparisons.
In this blog post, we will explore the Dutch National Flag algorithm in detail, including how it works, its applications, and its benefits.</description>
            <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:700/1*ZzXl4hi33T6jDpngN1OqBA.png" alt=""></p>
<p>The Dutch National Flag algorithm is a popular and efficient sorting technique for problems where elements can be divided into three distinct categories. Named after the Dutch national flag, where there are three horizontal stripes of different colors, this algorithm elegantly sorts an array of items into three groups with minimal swaps and comparisons.</p>
<p>In this blog post, we will explore the Dutch National Flag algorithm in detail, including how it works, its applications, and its benefits.</p>
<h2 id="what-is-the-dutch-national-flag-algorithm">What is the Dutch National Flag Algorithm?</h2>
<p>The Dutch National Flag problem was introduced by Edsger W. Dijkstra in 1976. The problem asks to sort an array of elements where each element is one of three distinct categories (usually represented as 0, 1, and 2).</p>
<p>The algorithm is most commonly used to sort an array containing three different types of values, such as:</p>
<ul>
<li><strong>0</strong> (Red)</li>
<li><strong>1</strong> (White)</li>
<li><strong>2</strong> (Blue)</li>
</ul>
<p>For example, the problem might look like this: You are given an array of integers containing only <code>0</code>, <code>1</code>, and <code>2</code>, and you need to sort the array such that all <code>0</code>s come first, followed by <code>1</code>s, and <code>2</code>s last.</p>
<h2 id="how-does-the-dutch-national-flag-algorithm-work">How Does the Dutch National Flag Algorithm Work?</h2>
<p>The Dutch National Flag algorithm uses a <strong>three-way partitioning</strong> strategy. It works by maintaining three pointers:</p>
<ul>
<li><strong>Low</strong>: Points to the position where the next <code>0</code> should be placed.</li>
<li><strong>Mid</strong>: Points to the current element being considered.</li>
<li><strong>High</strong>: Points to the position where the next <code>2</code> should be placed.</li>
</ul>
<p>Here’s how the algorithm operates:</p>
<ol>
<li>Start with <code>Low</code> at the beginning, <code>Mid</code> at the start of the array, and <code>High</code> at the end of the array.</li>
<li>Traverse the array from <code>Mid</code> to <code>High</code>:</li>
</ol>
<ul>
<li>If the current element is <code>0</code>, swap it with the element at <code>Low</code> and increment both <code>Low</code> and <code>Mid</code>.</li>
<li>If the current element is <code>1</code>, just move <code>Mid</code> forward.</li>
<li>If the current element is <code>2</code>, swap it with the element at <code>High</code> and decrement <code>High</code>.</li>
</ul>
<p>This partitioning process ensures that, at the end, all <code>0</code>s are in the left section, <code>1</code>s are in the middle section, and <code>2</code>s are in the right section.</p>
<h2 id="visualization">Visualization</h2>
<p>Let’s visualize the process with an example.</p>
<p><strong>Example Input</strong>:</p>
<p>[2, 0, 1, 2, 1, 0]</p>
<ul>
<li>Initially:<br>
<code>Low = 0, Mid = 0, High = 5 Array = [2, 0, 1, 2, 1, 0]</code></li>
</ul>
<p><strong>First iteration</strong> (<code>Mid = 0</code>, <code>array[Mid] = 2</code>):</p>
<ul>
<li>Swap <code>array[Mid]</code> with <code>array[High]</code>.</li>
<li>After the swap:</li>
<li><code>Array = [0, 0, 1, 2, 1, 2]</code></li>
<li>Decrement <code>High</code> to 4.</li>
</ul>
<p><strong>Second iteration</strong> (<code>Mid = 0</code>, <code>array[Mid] = 0</code>):</p>
<ul>
<li>Swap <code>array[Mid]</code> with <code>array[Low]</code>.</li>
<li>After the swap:</li>
<li><code>Array = [0, 0, 1, 2, 1, 2]</code></li>
<li>Increment both <code>Low</code> and <code>Mid</code> to 1.</li>
</ul>
<p><strong>Third iteration</strong> (<code>Mid = 1</code>, <code>array[Mid] = 0</code>):</p>
<ul>
<li>Swap <code>array[Mid]</code> with <code>array[Low]</code> (already in place).</li>
<li>Increment <code>Low</code> and <code>Mid</code> to 2.</li>
</ul>
<p><strong>Fourth iteration</strong> (<code>Mid = 2</code>, <code>array[Mid] = 1</code>):</p>
<ul>
<li>No swap required, just increment <code>Mid</code> to 3.</li>
</ul>
<p><strong>Fifth iteration</strong> (<code>Mid = 3</code>, <code>array[Mid] = 2</code>):</p>
<ul>
<li>Swap <code>array[Mid]</code> with <code>array[High]</code>.</li>
<li>After the swap</li>
<li><code>Array = [0, 0, 1, 1, 2, 2]</code></li>
<li>Decrement <code>High</code> to 3.</li>
</ul>
<p>At this point, <code>Mid</code> is greater than <code>High</code>, so the algorithm terminates.</p>
<p><strong>Final Sorted Array</strong>:</p>
<p>[0, 0, 1, 1, 2, 2]</p>
<h2 id="time-complexity">Time Complexity</h2>
<p>The Dutch National Flag algorithm runs in <strong>O(n)</strong> time complexity, where <code>n</code> is the number of elements in the array. This is because:</p>
<ul>
<li>Each element is processed exactly once.</li>
<li>The algorithm uses a constant amount of space, making its space complexity <strong>O(1)</strong>.</li>
</ul>
<h2 id="when-should-you-use-the-dutch-national-flag-algorithm">When Should You Use the Dutch National Flag Algorithm?</h2>
<p>The Dutch National Flag algorithm is particularly useful when you are sorting an array that only contains three distinct values. Here are some typical use cases:</p>
<ol>
<li><strong>Sorting colors</strong>: This is the original problem, where you have an array of colors (e.g., red, white, and blue) and need to sort them.</li>
<li><strong>Partitioning arrays</strong>: This can be used for problems like segregating even and odd numbers, or partitioning numbers into different categories based on conditions.</li>
<li><strong>Three-way comparison</strong>: Any problem that requires partitioning into three categories can benefit from this efficient algorithm.</li>
</ol>
<h2 id="code-example-in-java">Code Example in Java</h2>
<p>Here’s the Java code implementing the Dutch National Flag algorithm:</p>
<pre><code>public class DutchNationalFlag {
    public static void sortColors(int[] nums) {
        int low = 0, mid = 0, high = nums.length - 1;
        while (mid &lt;= high) {
            if (nums[mid] == 0) {
                // Swap nums[low] and nums[mid]
                int temp = nums[low];
                nums[low] = nums[mid];
                nums[mid] = temp;
                low++;
                mid++;
            } else if (nums[mid] == 1) {
                mid++;
            } else {
                // Swap nums[mid] and nums[high]
                int temp = nums[mid];
                nums[mid] = nums[high];
                nums[high] = temp;
                high--;
            }
        }
    }
public static void main(String[] args) {
        int[] nums = {2, 0, 1, 2, 1, 0};
        sortColors(nums);
        System.out.println(Arrays.toString(nums));
    }
}
</code></pre>
<h2 id="example">Example</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:513/1*4UeQPLUD5TN1VE2nEZN_rQ.jpeg" alt=""></p>
<h2 id="conclusion">Conclusion</h2>
<p>The Dutch National Flag algorithm is a powerful, efficient way to sort arrays with three distinct values. By maintaining three pointers, it sorts the array in a single pass, making it much faster than traditional sorting algorithms when dealing with limited categories.</p>
<p>Its linear time complexity and constant space complexity make it a great choice for problems where you need to partition arrays into three groups. Whether you’re sorting colors, separating even and odd numbers, or solving other partitioning problems, this algorithm provides an elegant solution.</p>
<h3 id="further-reading">Further Reading</h3>
<ul>
<li><a href="https://www.cs.utexas.edu/~EWD/ewd02xx/EWD214.PDF">Edsger W. Dijkstra’s original paper</a></li>
<li><a href="https://www.geeksforgeeks.org/dutch-national-flag-problem/">Algorithm visualizations</a></li>
</ul>
<p>If you have any questions about the Dutch National Flag algorithm or how to apply it to other problems, feel free to leave a comment below! Happy coding!</p>
]]></content>
        </item>
        
        <item>
            <title>Hypothesis Testing: Formulas and Widely Used Tests</title>
            <link>https://jyotsnad246.github.io/posts/2024/08/hypothesis-testing-formulas-and-widely-used-tests/</link>
            <pubDate>Fri, 16 Aug 2024 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2024/08/hypothesis-testing-formulas-and-widely-used-tests/</guid>
            <description>Introduction Hypothesis testing is a fundamental statistical technique used to make informed decisions and draw conclusions about populations based on sample data. It allows researchers to assess whether an observed effect is statistically significant or due to chance. In this article, we will explore the key concepts of hypothesis testing, delve into the formulas involved, and examine some commonly used tests.
Understanding Hypothesis Testing Hypothesis testing involves two competing hypotheses: the null hypothesis (H0) and the alternative hypothesis (Ha).</description>
            <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:562/1*XizeX86IAm4mIxieipZ06w.png" alt=""></p>
<h2 id="introduction"><strong>Introduction</strong></h2>
<p>Hypothesis testing is a fundamental statistical technique used to make informed decisions and draw conclusions about populations based on sample data. It allows researchers to assess whether an observed effect is statistically significant or due to chance. In this article, we will explore the key concepts of hypothesis testing, delve into the formulas involved, and examine some commonly used tests.</p>
<h2 id="understanding-hypothesis-testing">Understanding Hypothesis Testing</h2>
<p>Hypothesis testing involves two competing hypotheses: the null hypothesis (H0) and the alternative hypothesis (Ha). The null hypothesis represents the status quo or the absence of an effect, while the alternative hypothesis proposes a specific claim or research hypothesis.</p>
<h2 id="the-hypothesis-testing-process"><strong>The Hypothesis Testing Process</strong></h2>
<p><strong>1. Formulate the hypotheses:</strong></p>
<ul>
<li>Null Hypothesis (H0): No significant difference or effect exists.</li>
<li>Alternative Hypothesis (Ha): A specific difference or effect exists.</li>
</ul>
<p><strong>2. Set the significance level (α):</strong></p>
<ul>
<li>The significance level, denoted by α, is the probability of rejecting the null hypothesis when it is true.</li>
<li>Commonly used significance levels include 0.05 and 0.01.</li>
</ul>
<p><strong>3. Collect and analyze the data:</strong></p>
<ul>
<li>Gather a representative sample and collect relevant data.</li>
<li>Compute the test statistic, which measures the degree of evidence against the null hypothesis.</li>
</ul>
<p><strong>4. Determine the critical region and critical value:</strong></p>
<ul>
<li>The critical region represents the extreme values of the test statistic that would lead to rejecting the null hypothesis.</li>
<li>The critical value is the dividing point that separates the critical region from the non-critical region.</li>
</ul>
<p><strong>5. Compare the test statistic and critical value:</strong></p>
<ul>
<li>If the test statistic falls within the critical region, the null hypothesis is rejected.</li>
<li>If the test statistic falls within the non-critical region, the null hypothesis is not rejected.</li>
</ul>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*XQHR-Ak4s3qamRNC8C_wkQ.png" alt=""></p>
<h2 id="commonly-used-tests">Commonly Used Tests</h2>
<ul>
<li>Z-Test: The Z-test is used when the sample size is large, and the population standard deviation is known. The test statistic (Z-score) is calculated using the formula: Z = (x̄ — μ) / (σ / √n) where x̄ is the sample mean, μ is the population mean, σ is the population standard deviation, and n is the sample size.</li>
<li>t-Test: The t-test is used when the population standard deviation is unknown, and the sample size is small. The test statistic (t-score) is calculated using the formula: t = (x̄ — μ) / (s / √n) where x̄ is the sample mean, μ is the population mean, s is the sample standard deviation, and n is the sample size.</li>
<li>Chi-Square Test: The chi-square test is used to determine if there is a significant association between categorical variables. The test statistic (χ²) is calculated using the formula: χ² = Σ((O — E)² / E) where O is the observed frequency, and E is the expected frequency.</li>
</ul>
<p>Here is a table summarizing the commonly used hypothesis testing methods along with their respective formulas:</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*QLevfA4jsgVTZZxK6NUnbA.png" alt=""></p>
<p>These tests provide researchers with powerful tools to analyze data and draw conclusions about population parameters. By applying the appropriate test based on the given conditions, researchers can make informed decisions and contribute to evidence-based knowledge in their respective fields.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Hypothesis testing is a powerful tool for researchers to evaluate the significance of their findings and make informed decisions. By understanding the key concepts and utilizing appropriate tests, researchers can draw reliable conclusions from their data. In this article, we discussed the hypothesis testing process, including formulating hypotheses, setting significance levels, analyzing data, and determining critical regions. Additionally, we explored three commonly used tests: the Z-test, t-test, and chi-square test, along with their respective formulas. By employing these techniques correctly, researchers can make confident and evidence-based conclusions in their studies.</p>
]]></content>
        </item>
        
        <item>
            <title>Mastering Model Evaluation: A Comprehensive Guide to Choosing and Interpreting Evaluation Metrics in Machine Learning</title>
            <link>https://jyotsnad246.github.io/posts/2024/07/mastering-model-evaluation-a-comprehensive-guide-to-choosing-and-interpreting-evaluation-metrics-in-machine-learning/</link>
            <pubDate>Fri, 19 Jul 2024 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2024/07/mastering-model-evaluation-a-comprehensive-guide-to-choosing-and-interpreting-evaluation-metrics-in-machine-learning/</guid>
            <description>Introduction In the field of machine learning, evaluating the performance of models is essential for understanding their efficacy and making informed decisions. Evaluation metrics provide quantitative measures to assess how well a machine learning model performs on specific tasks such as classification, regression, or clustering. In this article, we will explore the significance of evaluation metrics and discuss different types commonly used in machine learning tasks.
Classification Evaluation Metrics In classification tasks, models are trained to predict predefined classes or labels for input data.</description>
            <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:700/0*SJGvtEsalkRr1J6Q" alt=""></p>
<h2 id="introduction">Introduction</h2>
<p>In the field of machine learning, evaluating the performance of models is essential for understanding their efficacy and making informed decisions. Evaluation metrics provide quantitative measures to assess how well a machine learning model performs on specific tasks such as classification, regression, or clustering. In this article, we will explore the significance of evaluation metrics and discuss different types commonly used in machine learning tasks.</p>
<h2 id="classification-evaluation-metrics">Classification Evaluation Metrics</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:498/1*J-UI3Un1dy-bzFMolyt-6g.png" alt=""></p>
<p>In classification tasks, models are trained to predict predefined classes or labels for input data. While accuracy is a fundamental metric that measures the percentage of correctly predicted instances, it may not provide a comprehensive picture of model performance, especially when dealing with imbalanced datasets. To account for class imbalances, additional metrics such as precision, recall, and F1-score are widely employed.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:578/1*CSsGa2qQotZ3q_3zeaWpXw.png" alt=""></p>
<h3 id="1-accuracy"><strong>1. Accuracy</strong>:</h3>
<p>Accuracy measures the percentage of correctly predicted instances out of the total instances. Formula: Accuracy = (Number of correctly predicted instances) / (Total number of instances)</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*IG0ET08Q5_0zEF1U9Pm0qw.png" alt=""></p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*le0_sYE-uU5xY0tAhraRRg.png" alt=""></p>
<h3 id="2-precision">2. Precision:</h3>
<p>Precision represents the percentage of correctly predicted positive instances out of the total predicted positive instances. Formula: Precision = (Number of true positives) / (Number of true positives + Number of false positives)</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*nN8z22YSR1HQwCICgrNvIg.png" alt=""></p>
<h3 id="3-recall-sensitivity-or-true-positive-rate">3. Recall (Sensitivity or True Positive Rate):</h3>
<p>Recall measures the percentage of correctly predicted positive instances out of the total actual positive instances. Formula: Recall = (Number of true positives) / (Number of true positives + Number of false negatives)</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*3ZYOyTqxPfbrfw1hh93tQA.png" alt=""></p>
<h3 id="4-f1-score">4. F1-score:</h3>
<p>The F1-score is the harmonic mean of precision and recall, providing a balanced measure of model performance that considers both false positives and false negatives. Formula: F1-score = 2 _ (Precision _ Recall) / (Precision + Recall)</p>
<p><img src="https://miro.medium.com/v2/resize:fit:656/1*aZ9tNeercx1SuDgFvgPVxw.png" alt=""></p>
<h3 id="when-to-choose-which-metric-for-classification">When to choose which metric for classification:</h3>
<blockquote>
<ul>
<li>
<p>Accuracy is suitable for balanced datasets, where classes are represented equally.</p>
</li>
<li>
<p>Precision is useful when the focus is on minimizing false positives.</p>
</li>
<li>
<p>Recall is beneficial when the emphasis is on minimizing false negatives.</p>
</li>
<li>
<p>F1-score provides a balanced measure when both false positives and false negatives are important.</p>
</li>
</ul>
</blockquote>
<h2 id="regression-evaluation-metrics">Regression Evaluation Metrics</h2>
<p>In regression tasks, models aim to predict continuous numerical values instead of discrete classes. The most commonly used evaluation metrics for regression are mean squared error (MSE) and mean absolute error (MAE).</p>
<p><img src="https://miro.medium.com/v2/resize:fit:480/1*fGIzkUpUo6igK9_HvD6VrA.png" alt=""></p>
<h3 id="1-mean-squared-error-mse">1. Mean Squared Error (MSE):</h3>
<p>MSE calculates the average squared difference between the actual and predicted values, providing insight into the overall error of the model. Formula: MSE = (1/n) * Σ(y — ŷ)², where y is the actual value and ŷ is the predicted value, and n is the total number of instances.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:667/1*Q9v2bBtonWSP8W_fwuDFMA.png" alt=""></p>
<h3 id="2-mean-absolute-error-mae">2. Mean Absolute Error (MAE):</h3>
<p>MAE computes the average absolute difference between the actual and predicted values, giving a robust measure of the average difference. Formula: MAE = (1/n) * Σ|y — ŷ|, where y is the actual value and ŷ is the predicted value, and n is the total number of instances.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:672/1*p83A45xfMsKRmYJq6AA26w.png" alt=""></p>
<h3 id="3-root-mean-squared-error-rmse">3. Root Mean Squared Error (RMSE):</h3>
<p>RMSE is the square root of the mean squared error, providing a measure of the average magnitude of the errors. Formula: RMSE = √(MSE)</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*CakMn3IQZhn_Ce6hsrCsRw.png" alt=""></p>
<h3 id="4-root-mean-squared-log-error-rmsle">4. Root Mean Squared Log Error (RMSLE):</h3>
<p>RMSLE calculates the square root of the mean squared logarithmic difference between the predicted and actual values, useful for tasks where the target variable has a large range. Formula: RMSLE = √(1/n) * Σ(log(1 + y) — log(1 + ŷ))², where y is the actual value, ŷ is the predicted value, and n is the total number of instances.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*Gw0Y6BjL3nju3R3LG6DjLA.png" alt=""></p>
<h3 id="5-r2-score-r-squared-or-coefficient-of-determination">5. R2 Score (R Squared or Coefficient of Determination):</h3>
<p>R2 score, also known as the coefficient of determination, measures the proportion of the variance in the dependent variable that is predictable from the independent variables. Formula: R2 = 1 — (Sum of squared residuals / Total sum of squares)</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*O8OQ0RJ0h7MOxqOasRvSlA.png" alt=""></p>
<h3 id="6-adjusted-r-squared">6. Adjusted R Squared:</h3>
<p>Adjusted R squared is a modified version of R squared that takes into account the number of predictors in the model, providing a measure of the proportion of the variance explained by the model. Formula: Adjusted R squared = 1 — ((1 — R²) * (n — 1)) / (n — p — 1), where R squared is the coefficient of determination, n is the total number of instances, and p is the number of predictors. It is always less than or equal to R2 Score.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*tuArYLFDTR1AMWHJeSQ_Dw.png" alt=""></p>
<h3 id="when-to-choose-which-metric-for-regression">When to choose which metric for regression:</h3>
<blockquote>
<p>MSE is commonly used and suitable when the emphasis is on penalizing larger errors, making it more sensitive to outliers.</p>
<p>MAE provides a more robust measure, as it considers the absolute difference without squaring the errors, making it less sensitive to outliers.</p>
<p>RMSE is similar to MSE but expressed in the original units of the target variable, making it more interpretable.</p>
<p>RMSLE is useful when the target variable has a large range and you want to penalize underestimation and overestimation equally.</p>
<p>R2 score is useful for understanding the proportion of the variance explained by the model, with higher values indicating a better fit.</p>
<p>Adjusted R squared is valuable when you want to account for the number of predictors and evaluate the model’s explanatory power.</p>
</blockquote>
<h2 id="clustering-evaluation-metrics">Clustering Evaluation Metrics</h2>
<p>Clustering algorithms group similar data points together based on their inherent characteristics. Evaluating the performance of clustering algorithms can be challenging as there are no predefined labels to compare against. However, certain metrics can provide useful insights.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:452/1*3i9gEs_7suQv_S1j9Wo02Q.png" alt=""></p>
<h3 id="1-silhouette-coefficient">1. Silhouette Coefficient:</h3>
<p>The silhouette coefficient measures the compactness and separation of clusters. It assigns a score to each data point based on its proximity to points in its own cluster and other clusters. Formula: Silhouette Coefficient = (b — a) / max(a, b), where a is the mean distance between a data point and other points in the same cluster, and b is the mean distance between the data point and points in the nearest neighboring cluster.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*BxbM-w5eWx_BaIsRRn5COA.png" alt=""></p>
<h3 id="2-davies-bouldin-index">2. Davies-Bouldin Index:</h3>
<p>The Davies-Bouldin index calculates the average similarity between clusters while considering their separation. Smaller values indicate better clustering performance. Formula: Davies-Bouldin Index = (1/n) * Σ(maximum similarity), where n is the total number of clusters.</p>
<h3 id="when-to-choose-which-metric-for-clustering">When to choose which metric for clustering:</h3>
<blockquote>
<p>The silhouette coefficient is useful when assessing the compactness and separation of clusters. Higher values (close to 1) indicate well-separated and compact clusters.</p>
<p>The Davies-Bouldin index is beneficial for evaluating the quality of clusters based on their similarity and separation. Smaller values indicate better clustering performance.</p>
</blockquote>
<h2 id="conclusion">Conclusion</h2>
<p>Evaluation metrics play a vital role in assessing the performance of machine learning models. They provide objective measures that enable researchers and practitioners to compare different algorithms and make informed decisions. Whether it’s classification, regression, or clustering, understanding the various evaluation metrics available is indispensable for ensuring accurate and effective evaluation of model performance. By leveraging the appropriate metrics, machine learning practitioners can fine-tune their models, improve their predictive capabilities, and drive innovation in the ever-evolving field of machine learning.</p>
]]></content>
        </item>
        
        <item>
            <title>Demystifying REST APIs: A Comprehensive Guide to Representational State Transfer</title>
            <link>https://jyotsnad246.github.io/posts/2024/02/demystifying-rest-apis-a-comprehensive-guide-to-representational-state-transfer/</link>
            <pubDate>Fri, 02 Feb 2024 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2024/02/demystifying-rest-apis-a-comprehensive-guide-to-representational-state-transfer/</guid>
            <description>In the ever-evolving landscape of web development, Representational State Transfer (REST) has emerged as a powerful architectural style for designing networked applications. REST APIs (Application Programming Interfaces) play a crucial role in facilitating structured communication between different software systems. This article aims to demystify the world of REST APIs, exploring their key concepts, advantages, components, and best practices.
Understanding REST: At its core, REST is an architectural style that relies on a stateless, client-server communication model.</description>
            <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:700/1*5b9URi8HKSr9A9f-jvmxCQ.png" alt=""></p>
<p>In the ever-evolving landscape of web development, Representational State Transfer (REST) has emerged as a powerful architectural style for designing networked applications. REST APIs (Application Programming Interfaces) play a crucial role in facilitating structured communication between different software systems. This article aims to demystify the world of REST APIs, exploring their key concepts, advantages, components, and best practices.</p>
<h2 id="understanding-rest">Understanding REST:</h2>
<p>At its core, REST is an architectural style that relies on a stateless, client-server communication model. This means that each HTTP request from a client to a server contains all the information necessary to understand and fulfill that request, promoting independence and scalability. The article delves into the significance of statelessness, emphasizing how it enhances automation and error-free interactions.</p>
<h2 id="key-principles-of-rest">Key Principles of REST:</h2>
<p>The article explores the fundamental principles that govern REST APIs, such as idempotency. Idempotent operations guarantee that performing an operation multiple times yields the same result as executing it once. The distinction between safe and unsafe HTTP methods is also discussed, shedding light on the importance of maintaining server state integrity.</p>
<h2 id="components-of-rest">Components of REST:</h2>
<p>To paint a comprehensive picture, the article breaks down the components of REST. From the original server (e.g., IIS, Apache Tomcat) to user agents (browsers and other APIs) and gateways (reverse proxies), each component’s role in facilitating seamless communication is elucidated. Connectors, as interfaces that components use to perform work, are explored in detail.</p>
<h2 id="authentication-and-authorization">Authentication and Authorization:</h2>
<p>The article emphasizes the critical role of security in REST APIs, particularly through the use of authentication and authorization mechanisms. The use of tokens, such as JSON Web Tokens (JWT), for secure and authorized communication is discussed, providing insights into best practices for safeguarding sensitive data.</p>
<h2 id="rest-api-endpoints-and-operations">REST API Endpoints and Operations:</h2>
<p>A deep dive into the anatomy of REST API calls is provided, elucidating the importance of defining endpoints. The CRUD operations (Create, Read, Update, Delete) are explored in the context of object manipulation, and the article illustrates how these operations contribute to the overall functionality of an API.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*h_AuOMQultfI9XmjQfeMYA.png" alt=""></p>
<h2 id="http-methods-in-rest">HTTP Methods in REST:</h2>
<h3 id="1-get-method">1. GET Method:</h3>
<p>The GET method is used to retrieve information from the server. When a client makes a GET request, it is asking the server to return a representation of a resource. This operation is idempotent, meaning multiple identical requests will have the same result, and it is considered a safe operation as it doesn’t modify the state of the server.</p>
<p>Example:</p>
<pre><code>GET /employeeSystem/employee/123
</code></pre>
<p>Response:</p>
<pre><code>{
    &quot;empID&quot;: 123,
    &quot;empName&quot;: &quot;Tushar&quot;
}
</code></pre>
<h3 id="2-put-method">2. PUT Method:</h3>
<p>PUT is employed to update or create a resource on the server. It requires the client to send the entire updated representation of the resource, replacing the existing one. Like GET, PUT is idempotent — multiple identical requests will yield the same result.</p>
<p>Example:</p>
<pre><code>PUT /employeeSystem/employee/123
</code></pre>
<p>Request Body:</p>
<pre><code>{
    &quot;empID&quot;: 123,
    &quot;empName&quot;: &quot;UpdatedTushar&quot;
}
</code></pre>
<h3 id="3-post-method">3. POST Method:</h3>
<p>POST is used to submit data to be processed to a specified resource. It often results in the creation of a new resource on the server. Unlike PUT, POST is not idempotent, meaning multiple identical requests might lead to different outcomes.</p>
<p>Example:</p>
<pre><code>POST /employeeSystem/employee
</code></pre>
<p>Request Body:</p>
<pre><code>{
    &quot;empName&quot;: &quot;NewEmployee&quot;
}
</code></pre>
<h3 id="4-patch-method">4. PATCH Method:</h3>
<p>PATCH is similar to PUT but is used for making partial updates to a resource. It applies modifications to the existing resource without requiring the client to send the entire representation. PATCH is not guaranteed to be idempotent.</p>
<p>Example:</p>
<pre><code>PATCH /employeeSystem/employee/123
</code></pre>
<p>Request Body:</p>
<pre><code>{
    &quot;empName&quot;: &quot;PatchedTushar&quot;
}
</code></pre>
<h3 id="5-delete-method">5. DELETE Method:</h3>
<p>DELETE is employed to request the removal of a resource from the server. It is idempotent — multiple identical requests will have the same result. However, like POST, it is not considered a safe operation as it alters the state of the server.</p>
<p>Example:</p>
<pre><code>DELETE /employeeSystem/employee/123
</code></pre>
<p>Understanding the nuances of these HTTP methods is crucial for designing RESTful APIs that adhere to the principles of predictability, reliability, and scalability. Proper utilization of these methods ensures that API interactions are both efficient and aligned with REST architectural constraints.</p>
<p>In the context of the previously discussed Movie Recommender System, these HTTP methods would be employed for operations like retrieving movie information (GET), updating user preferences (PUT), adding new movies to the database (POST), modifying existing movie details (PATCH), and removing movies from the recommendation list (DELETE). This integration of HTTP methods with practical examples enhances the clarity of how REST APIs function in real-world scenarios.</p>
<h2 id="conclusion">Conclusion:</h2>
<p>As the article concludes, readers gain a comprehensive understanding of REST APIs, from their foundational principles to practical implementation considerations. By demystifying the complexities surrounding REST, this guide empowers developers and enthusiasts to navigate the world of web development with confidence and clarity.</p>
]]></content>
        </item>
        
        <item>
            <title>Mojo 🔥 : Know Everything About the New Programming Language</title>
            <link>https://jyotsnad246.github.io/posts/2023/06/mojo-know-everything-about-the-new-programming-language/</link>
            <pubDate>Sun, 11 Jun 2023 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2023/06/mojo-know-everything-about-the-new-programming-language/</guid>
            <description>Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.
In the ever-evolving world of programming languages, a new contender has emerged, poised to revolutionize the way developers build software. Mojo Lang, a powerful and versatile programming language, has gained significant attention and popularity among programmers worldwide. In this article, we will delve into the features, strengths, and potential applications of Mojo Lang, providing an in-depth understanding of its capabilities and why it has captured the imagination of the programming community.</description>
            <content type="html"><![CDATA[<blockquote>
<p>Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.</p>
</blockquote>
<p><img src="https://miro.medium.com/v2/resize:fit:700/0*KRblIuaNEJ_OVil8" alt=""></p>
<p>In the ever-evolving world of programming languages, a new contender has emerged, poised to revolutionize the way developers build software. Mojo Lang, a powerful and versatile programming language, has gained significant attention and popularity among programmers worldwide. In this article, we will delve into the features, strengths, and potential applications of Mojo Lang, providing an in-depth understanding of its capabilities and why it has captured the imagination of the programming community.</p>
<h2 id="what-is-mojo-lang">What is Mojo Lang?</h2>
<p>Mojo Lang is a fast, modern, high-level programming language designed to be intuitive, efficient, and flexible. It combines the best features from various programming paradigms, making it suitable for a wide range of applications, from web development to artificial intelligence and everything in between. Mojo Lang is built upon a solid foundation of established programming languages, incorporating their strengths and addressing their limitations to provide a streamlined and elegant development experience.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*NXuTUno77pTm0F0vu22-Iw.png" alt=""></p>
<h2 id="running-mojo-programs">Running Mojo Programs</h2>
<p>Running a Mojo program is as straightforward as running a Python program from the terminal. You can execute a Mojo program by using the “mojo” command followed by the filename. For example, if you have a file named “hello.mojo” or “hello.🔥” (yes, the file extension can even be an emoji!), you can execute it using the following command:</p>
<pre><code>$ mojo hello.🔥
</code></pre>
<p>Note that you can use either the emoji extension or the “.mojo” suffix for Mojo files.</p>
<p>Mojo is designed as a superset of Python, so a lot of language features you are familiar with and the concepts that you know in Python translate directly to Mojo. For instance, a “Hello World” program in Mojo looks exactly as it does in Python:</p>
<pre><code>print(&quot;Hello Mojo!&quot;)
</code></pre>
<h2 id="key-features-of-mojo-lang">Key Features of Mojo Lang</h2>
<ol>
<li><strong>Conciseness and Readability:</strong> Mojo Lang emphasizes clean and expressive code, allowing developers to write programs that are easy to read and understand. Its syntax is designed to be concise, reducing unnecessary verbosity and promoting code clarity.</li>
<li><strong>Versatility and Flexibility:</strong> Mojo Lang supports multiple programming paradigms, including object-oriented, functional, and procedural programming. This versatility enables developers to choose the most suitable approach for their specific needs, fostering code reusability and adaptability.</li>
<li><strong>Memory Management:</strong> Mojo Lang employs automatic memory management through garbage collection, alleviating the burden of manual memory allocation and deallocation. This feature enhances code robustness and reduces the risk of memory leaks and other related issues.</li>
<li><strong>Strong Typing and Type Inference:</strong> Mojo Lang enforces strong typing, ensuring type safety and reducing runtime errors. Additionally, it incorporates type inference, allowing developers to omit explicit type declarations in certain situations, resulting in more concise code without sacrificing safety.</li>
<li><strong>Concurrency and Parallelism:</strong> Mojo Lang provides robust support for concurrent and parallel programming, making it easier to write efficient and scalable code. It offers built-in constructs for handling concurrency, such as threads and asynchronous programming, enabling developers to take full advantage of modern multi-core processors.</li>
</ol>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*Z3ad4WPFc76Kgc4SWUiw7Q.png" alt=""></p>
<p>For more info check — <a href="https://www.modular.com/mojo">https://www.modular.com/mojo</a></p>
<h2 id="conclusion">Conclusion</h2>
<p>In conclusion, Mojo Lang brings a host of powerful features to the programming landscape, enabling developers to write high-performance, safe, and portable code. With its emphasis on progressive types, zero cost abstractions, ownership and borrow checker, portable parametric algorithms, language-integrated auto-tuning, the full power of MLIR, parallel heterogeneous runtime, and fast compile times, Mojo Lang empowers developers to create efficient and reliable software solutions. Whether you’re a seasoned developer or just starting your programming journey, Mojo Lang offers a compelling set of tools and features to explore and utilize in your projects.</p>
<p><strong>References</strong></p>
<ul>
<li><a href="https://www.modular.com/mojo">https://www.modular.com/mojo</a></li>
<li><a href="https://docs.modular.com/mojo/">https://docs.modular.com/mojo/</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Segment Anything Model — SAM: A Game-Changer in Image Segmentation</title>
            <link>https://jyotsnad246.github.io/posts/2023/06/segment-anything-model-sam-a-game-changer-in-image-segmentation/</link>
            <pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate>
            
            <guid>https://jyotsnad246.github.io/posts/2023/06/segment-anything-model-sam-a-game-changer-in-image-segmentation/</guid>
            <description>Cupboard Segmented using Segment Anything Model by MetaAI — https://segment-anything.com/demo
Introduction In recent years, the field of computer vision has witnessed remarkable advancements, thanks to the emergence of foundation models and their ability to generalize across various tasks. The SegmentAnythingModel (SAM) is a groundbreaking vision foundational model that has garnered significant attention in the computer vision community. Trained on an extensive dataset, SAM exhibits an unprecedented capability to segment objects in images and videos.</description>
            <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:700/1*uVmHdCWdgwolXHy27B-uUA.png" alt=""></p>
<p>Cupboard Segmented using Segment Anything Model by MetaAI — <a href="https://segment-anything.com/demo">https://segment-anything.com/demo</a></p>
<h2 id="introduction">Introduction</h2>
<p>In recent years, the field of computer vision has witnessed remarkable advancements, thanks to the emergence of foundation models and their ability to generalize across various tasks. The SegmentAnythingModel (SAM) is a groundbreaking vision foundational model that has garnered significant attention in the computer vision community. Trained on an extensive dataset, SAM exhibits an unprecedented capability to segment objects in images and videos. In this blog post, we will explore the potential of SAM across different real-world applications, discuss its benefits, highlight its limitations, and explore future development prospects.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*ylwblktbanKm4N-uUXoifg.png" alt=""></p>
<h2 id="how-does-segment-anything-model-work-">How does Segment Anything Model work ?</h2>
<p>The Segment Anything Model (SAM) operates by combining three interconnected components: a promptable segmentation task, a segmentation model (SAM), and a data engine. Firstly, the promptable segmentation task is designed to enable zero-shot generalization. It involves returning a valid segmentation mask given any segmentation prompt, which can include foreground/background points, rough boxes or masks, free-form text, or any other information indicating what to segment in an image. SAM is a model architecture specifically designed to support flexible prompts and real-time mask computation. It consists of an image encoder, a prompt encoder, and a lightweight mask decoder. The image encoder computes an image embedding, the prompt encoder embeds prompts, and the mask decoder predicts segmentation masks based on the combined information. SAM can handle ambiguity by predicting multiple masks for a single prompt.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*P1OkbTAI-KJg4PzwkSd1FA.png" alt=""></p>
<h2 id="sams-versatility-in-real-world-applications">SAM’s Versatility in Real-World Applications</h2>
<p>SAM’s wide-ranging applications span natural images, agriculture, manufacturing, remote sensing, and healthcare. By conducting a series of intriguing investigations, researchers have gained valuable insights into SAM’s performance and its potential impact on practical image segmentation tasks. Let’s delve into some key findings:</p>
<p><strong>Excellent Generalization on Common Scenes</strong>: SAM demonstrates exceptional effectiveness in typical natural image scenarios. Regardless of the prompt mode used, SAM proves its ability to generalize well and accurately segment objects that prominently stand out from their surroundings. This underscores the strength of SAM’s model design and the vast and diverse training dataset it leverages.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*KBNSsz9xRU0BeZG0zVbJbw.png" alt=""></p>
<p>Segmentation done using SAM demo — <a href="https://segment-anything.com/demo">https://segment-anything.com/demo</a></p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*ti11LOlEwKhLcPjVUohoeA.png" alt=""></p>
<p>Airplane Segmented using SAM demo — <a href="https://segment-anything.com/demo">https://segment-anything.com/demo</a></p>
<p><strong>The Need for Strong Prior Knowledge</strong>: For complex scenes like crop segmentation and fundus image segmentation, SAM’s performance improves with additional manual prompts that incorporate prior knowledge. However, SAM tends to exhibit a foreground bias, which can lead to suboptimal results in certain scenarios. Overcoming this limitation would require further exploration and fine-tuning.</p>
<p><strong>Challenges in Low-Contrast Applications:</strong> SAM faces difficulties when segmenting objects with similar surrounding elements, especially transparent or camouflaged objects that seamlessly blend into their environment. In such cases, SAM may struggle to accurately distinguish the boundaries of these objects. Improving SAM’s robustness in low-contrast scenes represents an area of opportunity for future research.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*ux9r9hfhNvuHe_rP3tPknQ.png" alt=""></p>
<p>The above image is an example of low contrast images. Even after providing bounding box as a prompt we are unable to get proper segmented region.</p>
<p><strong>Limited Understanding of Professional Data:</strong> SAM’s performance in professional domains, such as medical and industrial scenarios, is often unsatisfactory. Even with click mode, both the user and the model need to possess domain-specific knowledge to achieve desirable results. SAM may fail to capture the nuances and complexities present in professional data, highlighting the need for specialized training and fine-tuning approaches.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*PoaM1tLh9kJEXfFg4Psa6Q.png" alt=""></p>
<p>Without prompt these are the results</p>
<p><img src="https://miro.medium.com/v2/resize:fit:700/1*mTkd2P7nJK-lhGbBEnxCEQ.png" alt=""></p>
<p>But with bounding box as a prompt the results are mush better</p>
<p><strong>Overcoming Challenges with Smaller and Irregular Objects:</strong> Remote sensing and agriculture present additional complexities, such as irregular buildings and small-sized streets captured from aerial imaging sensors. SAM struggles to produce complete segmentations in such cases, as it may miss smaller or irregularly shaped objects. Addressing these challenges would require advancements in handling object scale and shape variations.</p>
<h2 id="future-prospects-for-sam-and-image-segmentation">Future Prospects for SAM and Image Segmentation</h2>
<p>Despite these limitations, SAM has laid a solid foundation for the future of image segmentation. Researchers and practitioners are actively working to overcome the challenges faced by SAM and push the boundaries of its capabilities. Some potential directions for future development include:</p>
<ol>
<li>Improving Robustness in Low-Contrast Scenes: Enhancing SAM’s ability to segment objects in low-contrast environments will significantly expand its applicability in real-world scenarios.</li>
<li>Specialized Training for Professional Domains: Developing domain-specific training approaches and incorporating specialized knowledge into SAM can enhance its performance in professional applications, such as medical imaging and industrial inspections.</li>
<li>Handling Smaller and Irregular Objects: Advancements in object detection and segmentation algorithms can help SAM better handle smaller and irregularly shaped objects, enabling more accurate and complete segmentations.</li>
<li>Expanding the Training Dataset: Continuously augmenting and diversifying the training dataset for SAM can enhance its generalization capabilities and improve performance on a wide range of segmentation tasks.</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>While SAM demonstrates remarkable capabilities in segmenting objects in various real-world applications, it is essential to acknowledge its limitations. SAM may face challenges in scenarios involving low contrast, professional data, and smaller or irregular objects. Understanding these limitations is crucial for practitioners and researchers to make informed decisions about its usage in specific contexts.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://arxiv.org/abs/2304.05750">https://arxiv.org/abs/2304.05750</a></li>
<li><a href="https://segment-anything.com/">https://segment-anything.com/</a></li>
<li><a href="https://scontent.fdel46-1.fna.fbcdn.net/v/t39.2365-6/10000000_900554171201033_1602411987825904100_n.pdf?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=3c67a6&amp;_nc_ohc=iMsE1fjDr4EAX-6Pu5L&amp;_nc_ht=scontent.fdel46-1.fna&amp;oh=00_AfDswz0GFPLXPyleR1C3YyX6VERKYssAmdubBOTi0Tld_A&amp;oe=648220A7">https://scontent.fdel46-1.fna.fbcdn.net/v/t39.2365-6/10000000_900554171201033_1602411987825904100_n.pdf?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=3c67a6&amp;_nc_ohc=iMsE1fjDr4EAX-6Pu5L&amp;_nc_ht=scontent.fdel46-1.fna&amp;oh=00_AfDswz0GFPLXPyleR1C3YyX6VERKYssAmdubBOTi0Tld_A&amp;oe=648220A7</a></li>
</ul>
]]></content>
        </item>
        
    </channel>
</rss>
